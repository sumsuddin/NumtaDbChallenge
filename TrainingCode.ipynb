{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Necessary Imports & Inits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8654,
     "status": "ok",
     "timestamp": 1529853648476,
     "user": {
      "displayName": "Md. Sumsuddin",
      "photoUrl": "//lh6.googleusercontent.com/-ELKy4PtkKxs/AAAAAAAAAAI/AAAAAAAAAAs/0dRC984RL_o/s50-c-k-no/photo.jpg",
      "userId": "100207404814063728855"
     },
     "user_tz": -360
    },
    "id": "oJ7UEnGcTx-E",
    "outputId": "76038958-9c7b-4a75-bce2-2bd086171957"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from fastai.imports import *\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "\n",
    "sz=180\n",
    "arch=resnext50\n",
    "bs=24\n",
    "DATASET_DIR = \"numta/\"\n",
    "GENERATED_OUTPUT_DIR = os.path.join(DATASET_DIR, \"Fastai_gen/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 865,
     "status": "ok",
     "timestamp": 1529853639747,
     "user": {
      "displayName": "Md. Sumsuddin",
      "photoUrl": "//lh6.googleusercontent.com/-ELKy4PtkKxs/AAAAAAAAAAI/AAAAAAAAAAs/0dRC984RL_o/s50-c-k-no/photo.jpg",
      "userId": "100207404814063728855"
     },
     "user_tz": -360
    },
    "id": "o5qDtnQ2laSc",
    "outputId": "19666d05-2f92-46b1-a23a-d33bf8e1c845"
   },
   "outputs": [],
   "source": [
    "# Declare constants which will be used while plotting the data\n",
    "FS_AXIS_LABEL=14\n",
    "FS_TITLE=17\n",
    "FS_TICKS=12\n",
    "FIG_WIDTH=20\n",
    "ROW_HEIGHT=3\n",
    "\n",
    "def imshow_group(x,y=None,y_pred=None,n_per_row=10):\n",
    "    '''helper function to visualize a group of images along with their categorical true labels (y) and prediction probabilities.\n",
    "    Args:\n",
    "        x: images\n",
    "        y: categorical true labels\n",
    "        y_pred: predicted class probabilities\n",
    "        n_per_row: number of images per row to be plotted\n",
    "    '''\n",
    "    n_sample=len(x)\n",
    "    img_dim=x.shape[1]\n",
    "    text_spacing = int(img_dim * 0.15)\n",
    "    j=np.ceil(float(n_sample)/n_per_row)\n",
    "    fig=plt.figure(figsize=(FIG_WIDTH,ROW_HEIGHT*j))\n",
    "    for i,img in enumerate(x):\n",
    "        plt.subplot(j,n_per_row,i+1)\n",
    "        plt.imshow(img)\n",
    "        if y is not None:\n",
    "                plt.title('true label: {}'.format(np.argmax(y[i])))\n",
    "        if y_pred is not None:\n",
    "            top_n=3 # top 3 predictions with highest probabilities\n",
    "            ind_sorted=np.argsort(y_pred[i])[::-1]\n",
    "            h=img_dim+text_spacing\n",
    "            for k in range(top_n):\n",
    "                string='pred: {} ({:.0f}%)\\n'.format(ind_sorted[k],y_pred[i,ind_sorted[k]]*100)\n",
    "                plt.text(img_dim/2, h, string, horizontalalignment='center',verticalalignment='center')\n",
    "                h+= text_spacing\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def shuffle_with_labels(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    from sklearn.utils import shuffle\n",
    "    return shuffle(a, b)\n",
    "\n",
    "def resize_image(image, target_size):\n",
    "    r = image.shape[0]\n",
    "    c = image.shape[1]\n",
    "                        \n",
    "    ratio = float(target_size)/max(r,c)\n",
    "    sz = (int(c*ratio), int(r*ratio))\n",
    "    \n",
    "    return cv2.resize(image, sz, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "def load_images(input_files, input_size, invert = False):\n",
    "    \n",
    "    x_batch = np.full([len(input_files), input_size, input_size, 3], 0, dtype=np.uint8)\n",
    "    for i,file_path in enumerate(input_files):\n",
    "        image_read = cv2.imread(file_path)\n",
    "        image_read = resize_image(image_read, input_size)\n",
    "        \n",
    "        image = np.full([input_size, input_size, 3], 0, dtype=np.uint8)\n",
    "        image[0:image_read.shape[0], 0:image_read.shape[1], :] = image_read\n",
    "        \n",
    "        x_batch[i] = image\n",
    "        \n",
    "    if (invert):\n",
    "        x_batch = 255 - x_batch\n",
    "    return x_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generation of Overlay Images** (we used fixed 5000 images for all the training which are attached. Also 4 and 0 were ignored while mirroring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def im_read(file_path, input_size):\n",
    "    image_read = cv2.imread(file_path)\n",
    "    image_read = resize_image(image_read, input_size)\n",
    "\n",
    "    image = np.full([input_size, input_size, 3], 0, dtype=np.uint8)\n",
    "    image[0:image_read.shape[0], 0:image_read.shape[1], :] = image_read\n",
    "    return image\n",
    "\n",
    "\n",
    "def overlay_on_image(image1, image2):\n",
    "    alpha = 0.2\n",
    "    beta = 0.8\n",
    "    gamma = 0.0\n",
    "    return cv2.addWeighted(cv2.flip(image1, 1), alpha, image2, beta, gamma)\n",
    "\n",
    "def get_random_overlay_images(image_files, image_labels, count):\n",
    "\n",
    "    ov_imgs = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in tqdm(range(count)):\n",
    "        \n",
    "        rnd1 = np.random.randint(len(image_files), size=1)\n",
    "        rnd2 = np.random.randint(len(image_files), size=1)\n",
    "        \n",
    "        if (image_labels[rnd1[0]] == 4 or image_labels[rnd1[0]] == 0):\n",
    "            continue\n",
    "        \n",
    "        img = overlay_on_image(\n",
    "            im_read(image_files[rnd1[0]], 180),\n",
    "            im_read(image_files[rnd2[0]], 180))\n",
    "\n",
    "        ov_imgs.append(img)\n",
    "        labels.append(image_labels[rnd2[0]])\n",
    "    return np.array(ov_imgs), np.array(labels)\n",
    "\n",
    "def generate_overlay_files():\n",
    "    ov_images, labels = get_random_overlay_images(X_data, Y_data, 5000)\n",
    "\n",
    "    \n",
    "    mkdir(GENERATED_OVERLAY_DIR)\n",
    "\n",
    "    from random import choice\n",
    "    from string import ascii_uppercase\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        subdir = os.path.join(GENERATED_OVERLAY_DIR, str(labels[i]))\n",
    "        mkdir(subdir)\n",
    "\n",
    "        des_filename = ''.join(choice(ascii_uppercase) for _ in range(12))\n",
    "        des_file_path = os.path.join(subdir, des_filename + \".png\")\n",
    "        cv2.imwrite(des_file_path, ov_images[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "train_data_aug = iaa.Sequential(\n",
    "    [\n",
    "        iaa.SomeOf((1, 3),\n",
    "            [\n",
    "                iaa.Affine(\n",
    "                    scale=(0.7, 1.1),\n",
    "                    translate_percent={\"x\": (-0.1, 0.1), \"y\": (0.1, 0.1)},\n",
    "                    rotate=(-30, 30),\n",
    "                    shear=(-30, 30),\n",
    "                    order=[0, 1],\n",
    "                    cval=(0, 0),\n",
    "                ),\n",
    "                iaa.OneOf([\n",
    "                    iaa.AdditiveGaussianNoise(\n",
    "                        loc=0, scale=(0.0, 0.15*255)\n",
    "                    ),\n",
    "                    iaa.SaltAndPepper(0.15),\n",
    "                    iaa.Salt(0.15)\n",
    "                ]),\n",
    "\n",
    "                iaa.OneOf([\n",
    "                    iaa.Dropout((0.01, 0.05)),\n",
    "                    iaa.CoarseDropout(\n",
    "                        (0.03, 0.06), size_percent=(0.02, 0.04)\n",
    "                    ),\n",
    "                ]),\n",
    "\n",
    "                iaa.OneOf([\n",
    "                        iaa.OneOf([\n",
    "                            iaa.GaussianBlur((3.0, 4.0)),\n",
    "                            iaa.AverageBlur(k=(5, 7)),\n",
    "                        ]),\n",
    "\n",
    "                        iaa.Add((-10, 10), per_channel=0.5),\n",
    "                    \n",
    "                        iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
    "                        \n",
    "                        iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5),\n",
    "                ]),\n",
    "            ],\n",
    "            # do all of the above augmentations in random order\n",
    "            random_order=True\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "def get_augmentation(images):\n",
    "    return train_data_aug.augment_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Data Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44124,
     "status": "ok",
     "timestamp": 1529853692709,
     "user": {
      "displayName": "Md. Sumsuddin",
      "photoUrl": "//lh6.googleusercontent.com/-ELKy4PtkKxs/AAAAAAAAAAI/AAAAAAAAAAs/0dRC984RL_o/s50-c-k-no/photo.jpg",
      "userId": "100207404814063728855"
     },
     "user_tz": -360
    },
    "id": "gBMBu8yA2ZqD",
    "outputId": "73410a70-08ce-4b41-8170-b59b72592db6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from shutil import copyfile\n",
    "import cv2\n",
    "\n",
    "def mkdir(output_dir):\n",
    "    if (not os.path.exists(output_dir)):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "def move_images(from_path, to_path, invert=False):\n",
    "    files = [f for f in os.listdir(from_path)]\n",
    "    for single_file in files:\n",
    "        source_file = os.path.join(from_path,single_file)\n",
    "        destination_file = os.path.join(to_path, single_file)\n",
    "        if invert:\n",
    "            image = 255 - cv2.imread(source_file)\n",
    "            cv2.imwrite(destination_file, image)\n",
    "        else:\n",
    "            copyfile(source_file, destination_file)\n",
    "            \n",
    "def split_in_single_test_dir():\n",
    "    test_subdir = os.path.join(GENERATED_OUTPUT_DIR, 'test')\n",
    "    mkdir(test_subdir)\n",
    "    for testset in test_datasets:\n",
    "        move_images(os.path.join(DATASET_DIR, testset), test_subdir)\n",
    "    for testset in test_datasets_inv:\n",
    "        move_images(os.path.join(DATASET_DIR, testset), test_subdir, invert=True)        \n",
    "        \n",
    "def separate_in_train_dir():\n",
    "    mkdir(GENERATED_OUTPUT_DIR)\n",
    "    train_subdir = os.path.join(GENERATED_OUTPUT_DIR, 'train')\n",
    "    mkdir(train_subdir)\n",
    "    for _, item in train.iterrows():\n",
    "        save_dir = os.path.join(train_subdir, str(item['digit']))\n",
    "        mkdir(save_dir)\n",
    "        source_file = os.path.join(DATASET_DIR, item['database name'], item['filename'])\n",
    "        destination_file = os.path.join(save_dir, item['filename'])\n",
    "        copyfile(source_file, destination_file)\n",
    "    for _, item in train_inv.iterrows():\n",
    "        save_dir = os.path.join(train_subdir, str(item['digit']))\n",
    "        mkdir(save_dir)\n",
    "        source_file = os.path.join(DATASET_DIR, item['database name'], item['filename'])\n",
    "        destination_file = os.path.join(save_dir, item['filename'])\n",
    "        copyfile(source_file, destination_file)\n",
    "        image = 255 - cv2.imread(source_file)\n",
    "        cv2.imwrite(destination_file, image)\n",
    "        \n",
    "def make_valid_set():\n",
    "\n",
    "    train_dir = os.path.join(GENERATED_OUTPUT_DIR, 'train/')\n",
    "    label_dirs = os.listdir(train_dir)\n",
    "    valid_subdir = os.path.join(GENERATED_OUTPUT_DIR, 'valid')\n",
    "    mkdir(valid_subdir)\n",
    "    for label_dir in label_dirs:\n",
    "        source_path = os.path.join(train_dir, label_dir)\n",
    "        dest_path = os.path.join(valid_subdir, label_dir)\n",
    "        mkdir(dest_path)\n",
    "        image_filenames = [f for f in os.listdir(os.path.join(train_dir,label_dir))]\n",
    "        for image_filename in image_filenames:\n",
    "            copyfile(os.path.join(source_path, image_filename), os.path.join(dest_path, image_filename))\n",
    "            break\n",
    "            #make it very small now. as we don't need it\n",
    "\n",
    "from tqdm import tqdm\n",
    "def generate_augmentation(training_dataset_dir):\n",
    "    label_dirs = os.listdir(training_dataset_dir)\n",
    "    for label_dir in label_dirs:\n",
    "        label_path = os.path.join(training_dataset_dir, label_dir)\n",
    "        image_files = np.array([f for f in os.listdir(label_path)])\n",
    "        for im_file in tqdm(image_files):\n",
    "            augmented_image = get_augmentation(np.expand_dims(cv2.imread(os.path.join(label_path,im_file)), axis=0))\n",
    "            cv2.imwrite(os.path.join(label_path, \"augmented_\" + im_file), np.squeeze(augmented_image))\n",
    "            augmented_image = get_augmentation(np.expand_dims(cv2.imread(os.path.join(label_path,im_file)), axis=0))\n",
    "            cv2.imwrite(os.path.join(label_path, \"augmented_1_\" + im_file), np.squeeze(augmented_image))\n",
    "            \n",
    "def copy_overlay_images():\n",
    "    train_subdir = os.path.join(GENERATED_OUTPUT_DIR, 'train')\n",
    "    mkdir(train_subdir)\n",
    "    db_dir = os.path.join(DATASET_DIR, 'overlays/')\n",
    "    label_dirs = os.listdir(db_dir)\n",
    "    for label_dir in label_dirs:\n",
    "        source_path = os.path.join(db_dir, label_dir)\n",
    "        dest_path = os.path.join(train_subdir, label_dir)\n",
    "        mkdir(dest_path)\n",
    "        image_filenames = [f for f in os.listdir(os.path.join(db_dir,label_dir))]\n",
    "        for image_filename in image_filenames:\n",
    "            copyfile(os.path.join(source_path, image_filename), os.path.join(dest_path, image_filename))\n",
    "\n",
    "\n",
    "train_set = [\"training-a.csv\", \"training-b.csv\", \"training-c.csv\", \"training-d.csv\"]\n",
    "train_set_inv = [\"training-e.csv\"]\n",
    "train = pd.concat([pd.read_csv(os.path.join(DATASET_DIR, x)) for x in train_set])\n",
    "train_inv = pd.concat([pd.read_csv(os.path.join(DATASET_DIR, x)) for x in train_set_inv])\n",
    "print (\"Generating training set\")\n",
    "separate_in_train_dir()\n",
    "print (\"Bringing overlay images\")\n",
    "copy_overlay_images()\n",
    "\n",
    "make_valid_set()\n",
    "\n",
    "test_datasets = ['testing-auga', 'testing-augc', 'testing-a', 'testing-b', 'testing-c', 'testing-d', 'testing-f']\n",
    "test_datasets_inv = ['testing-e']\n",
    "print (\"Generating test set\")\n",
    "split_in_single_test_dir()\n",
    "\n",
    "print (\"Augmenting train set\")\n",
    "#Don't re run without deleting previous augmentation first (same image will be augmented twise otherwise).\n",
    "generate_augmentation(os.path.join(GENERATED_OUTPUT_DIR, 'train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5659,
     "status": "ok",
     "timestamp": 1529853756929,
     "user": {
      "displayName": "Md. Sumsuddin",
      "photoUrl": "//lh6.googleusercontent.com/-ELKy4PtkKxs/AAAAAAAAAAI/AAAAAAAAAAs/0dRC984RL_o/s50-c-k-no/photo.jpg",
      "userId": "100207404814063728855"
     },
     "user_tz": -360
    },
    "id": "9bnTkAYydG11",
    "outputId": "101fff60-29e1-42e8-cb8a-43f86fa36f43"
   },
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(arch, sz)\n",
    "data = ImageClassifierData.from_paths(GENERATED_OUTPUT_DIR, test_name='test', tfms=tfms, bs=bs, num_workers=4)\n",
    "learn = ConvLearner.pretrained(arch, data, ps=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 580781,
     "status": "ok",
     "timestamp": 1529818561808,
     "user": {
      "displayName": "Md. Sumsuddin",
      "photoUrl": "//lh6.googleusercontent.com/-ELKy4PtkKxs/AAAAAAAAAAI/AAAAAAAAAAs/0dRC984RL_o/s50-c-k-no/photo.jpg",
      "userId": "100207404814063728855"
     },
     "user_tz": -360
    },
    "id": "kSHY0hPgdHX-",
    "outputId": "fe3be3b3-2208-478b-ef2e-484c4e935e82"
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "learn.fit(lr, 1)\n",
    "learn.precompute=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1160801,
     "status": "ok",
     "timestamp": 1529819722670,
     "user": {
      "displayName": "Md. Sumsuddin",
      "photoUrl": "//lh6.googleusercontent.com/-ELKy4PtkKxs/AAAAAAAAAAI/AAAAAAAAAAs/0dRC984RL_o/s50-c-k-no/photo.jpg",
      "userId": "100207404814063728855"
     },
     "user_tz": -360
    },
    "id": "XRytR9H1dSlN",
    "outputId": "a3757338-3273-48bf-da48-2d023882868b"
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 2, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1529861617415,
     "user": {
      "displayName": "Md. Sumsuddin",
      "photoUrl": "//lh6.googleusercontent.com/-ELKy4PtkKxs/AAAAAAAAAAI/AAAAAAAAAAs/0dRC984RL_o/s50-c-k-no/photo.jpg",
      "userId": "100207404814063728855"
     },
     "user_tz": -360
    },
    "id": "ZSAK2rCDdYN8",
    "outputId": "8186c53a-3152-4994-fbc8-ca518f210edd"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "lr=np.array([lr/9,lr/3,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4787868,
     "status": "ok",
     "timestamp": 1529866405362,
     "user": {
      "displayName": "Md. Sumsuddin",
      "photoUrl": "//lh6.googleusercontent.com/-ELKy4PtkKxs/AAAAAAAAAAI/AAAAAAAAAAs/0dRC984RL_o/s50-c-k-no/photo.jpg",
      "userId": "100207404814063728855"
     },
     "user_tz": -360
    },
    "id": "wYFPMwwLdatV",
    "outputId": "9698f230-8d38-4eb8-9162-acac5fac91bc"
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 6, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1865,
     "status": "ok",
     "timestamp": 1529866433449,
     "user": {
      "displayName": "Md. Sumsuddin",
      "photoUrl": "//lh6.googleusercontent.com/-ELKy4PtkKxs/AAAAAAAAAAI/AAAAAAAAAAs/0dRC984RL_o/s50-c-k-no/photo.jpg",
      "userId": "100207404814063728855"
     },
     "user_tz": -360
    },
    "id": "l7pXg8PBdcIe",
    "outputId": "02cc6b7a-838f-4d02-fdad-d9ef5c2c0e31"
   },
   "outputs": [],
   "source": [
    "#learn.save('180_all_50_lrg5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1284,
     "status": "ok",
     "timestamp": 1529866437169,
     "user": {
      "displayName": "Md. Sumsuddin",
      "photoUrl": "//lh6.googleusercontent.com/-ELKy4PtkKxs/AAAAAAAAAAI/AAAAAAAAAAs/0dRC984RL_o/s50-c-k-no/photo.jpg",
      "userId": "100207404814063728855"
     },
     "user_tz": -360
    },
    "id": "QS5ZPbejdhTs",
    "outputId": "72c9d260-13e7-471c-9820-04cd0e4ed80e"
   },
   "outputs": [],
   "source": [
    "#learn.load('180_all_50_lrg')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Dur0bJzRTP7m"
   ],
   "default_view": {},
   "name": "FastaiHandwritten.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
